{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # importing the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading all csv into dataframes\n",
    "test_task_data = pd.read_csv(\"test_task.csv\")\n",
    "banned_domains_data = pd.read_csv(\"banned_domains.csv\")\n",
    "banned_words_data = pd.read_csv(\"banned_words.csv\")\n",
    "db_domains_data = pd.read_csv(\"db_domains.csv\")\n",
    "funding_data = pd.read_csv(\"funding_data.csv\", dtype={\n",
    "    'uuid': 'str',\n",
    "    'funding_round': 'str',\n",
    "    'money_raised': 'float64',\n",
    "    'company_name': 'str'\n",
    "}, parse_dates=['funding_date'], dayfirst=True) # specifying the datatypes to avoid mixed data types warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>uuid</th>\n",
       "      <th>website</th>\n",
       "      <th>Name</th>\n",
       "      <th>description</th>\n",
       "      <th>valuation_usd</th>\n",
       "      <th>categories</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5639c94c-408b-450a-9694-df238f6d9da9</td>\n",
       "      <td>https://www.perplexity.ai</td>\n",
       "      <td>Perplexity AI</td>\n",
       "      <td>Perplexity is a search engine platform that us...</td>\n",
       "      <td>5.200000e+08</td>\n",
       "      <td>[{'entity_def_id': 'category', 'permalink': 'a...</td>\n",
       "      <td>[{'permalink': 'san-francisco-california', 'uu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>00e32424-3cc3-4798-8361-78914c212fb0</td>\n",
       "      <td>https://mistral.ai</td>\n",
       "      <td>Mistral AI</td>\n",
       "      <td>Mistral AI is a platform that assembles team t...</td>\n",
       "      <td>1.999462e+09</td>\n",
       "      <td>[{'entity_def_id': 'category', 'permalink': 'a...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>c8326e69-b364-44af-a7a7-1f9239d532f1</td>\n",
       "      <td>https://robinai.co.uk</td>\n",
       "      <td>Robin AI</td>\n",
       "      <td>Robin AI is a legal infrastructure business th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'entity_def_id': 'category', 'permalink': 'a...</td>\n",
       "      <td>[{'permalink': 'london-england', 'uuid': 'aad1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>cf2c678c-b81a-80c3-10d1-9c5e76448e51</td>\n",
       "      <td>https://www.openai.com</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>OpenAI is an AI research and deployment compan...</td>\n",
       "      <td>2.900000e+10</td>\n",
       "      <td>[{'entity_def_id': 'category', 'permalink': 'a...</td>\n",
       "      <td>[{'permalink': 'san-francisco-california', 'uu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0f3fd8ce-9fe3-d6bd-d243-ffdf2fcfb012</td>\n",
       "      <td>http://www.startengine.com</td>\n",
       "      <td>StartEngine</td>\n",
       "      <td>StartEngine is an equity crowdfunding platform...</td>\n",
       "      <td>1.200000e+08</td>\n",
       "      <td>[{'entity_def_id': 'category', 'permalink': 'c...</td>\n",
       "      <td>[{'permalink': 'los-angeles-california', 'uuid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                  uuid  \\\n",
       "0           0  5639c94c-408b-450a-9694-df238f6d9da9   \n",
       "1           1  00e32424-3cc3-4798-8361-78914c212fb0   \n",
       "2           2  c8326e69-b364-44af-a7a7-1f9239d532f1   \n",
       "3           3  cf2c678c-b81a-80c3-10d1-9c5e76448e51   \n",
       "4           4  0f3fd8ce-9fe3-d6bd-d243-ffdf2fcfb012   \n",
       "\n",
       "                      website           Name  \\\n",
       "0   https://www.perplexity.ai  Perplexity AI   \n",
       "1          https://mistral.ai     Mistral AI   \n",
       "2       https://robinai.co.uk       Robin AI   \n",
       "3      https://www.openai.com         OpenAI   \n",
       "4  http://www.startengine.com    StartEngine   \n",
       "\n",
       "                                         description  valuation_usd  \\\n",
       "0  Perplexity is a search engine platform that us...   5.200000e+08   \n",
       "1  Mistral AI is a platform that assembles team t...   1.999462e+09   \n",
       "2  Robin AI is a legal infrastructure business th...            NaN   \n",
       "3  OpenAI is an AI research and deployment compan...   2.900000e+10   \n",
       "4  StartEngine is an equity crowdfunding platform...   1.200000e+08   \n",
       "\n",
       "                                          categories  \\\n",
       "0  [{'entity_def_id': 'category', 'permalink': 'a...   \n",
       "1  [{'entity_def_id': 'category', 'permalink': 'a...   \n",
       "2  [{'entity_def_id': 'category', 'permalink': 'a...   \n",
       "3  [{'entity_def_id': 'category', 'permalink': 'a...   \n",
       "4  [{'entity_def_id': 'category', 'permalink': 'c...   \n",
       "\n",
       "                                            location  \n",
       "0  [{'permalink': 'san-francisco-california', 'uu...  \n",
       "1                                                NaN  \n",
       "2  [{'permalink': 'london-england', 'uuid': 'aad1...  \n",
       "3  [{'permalink': 'san-francisco-california', 'uu...  \n",
       "4  [{'permalink': 'los-angeles-california', 'uuid...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_task_data.head() # Reading first five rows of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Unnamed: 0     10000 non-null  int64  \n",
      " 1   uuid           10000 non-null  object \n",
      " 2   website        9977 non-null   object \n",
      " 3   Name           10000 non-null  object \n",
      " 4   description    9832 non-null   object \n",
      " 5   valuation_usd  1920 non-null   float64\n",
      " 6   categories     9985 non-null   object \n",
      " 7   location       9995 non-null   object \n",
      "dtypes: float64(1), int64(1), object(6)\n",
      "memory usage: 625.1+ KB\n"
     ]
    }
   ],
   "source": [
    "test_task_data.info() # Getting infomation on all the columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) Remove all rows with duplicate uuids or websites (leave only one from every duplicate group)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing rows with duplicate entities under uuid and website columns\n",
    "test_task_data = test_task_data.drop_duplicates(subset=[\"uuid\", \"website\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) Remove the rows with no website, description, category or location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing rows with missing values under any of the following columns\n",
    "test_task_data = test_task_data.dropna(subset=['website', 'description', 'categories', 'location'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3) Remove all rows where valuation is equal to or exceeds 1 billion dollars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing all rows where where valuation is 1 billion or more\n",
    "test_task_data = test_task_data[~(test_task_data['valuation_usd'] >= 1_000_000_000)] # using bitwise negation to achieve this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4) Remove the rows with entities which contain uuids or websites from db_domains.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing all rows with uuids or websites in db_domains_data\n",
    "\n",
    "uuids_to_remove = db_domains_data['uuid_cb'].dropna().unique() # getting unique uuids\n",
    "websites_to_remove = db_domains_data['url'].dropna().unique() # getting unique websites\n",
    "\n",
    "# filtering the dataframe and removing all rows where uuid or website have values in the extracted uuids and websites from bd_domains_data\n",
    "test_task_data = test_task_data[~(test_task_data['uuid'].isin(uuids_to_remove) | \n",
    "                                          test_task_data['website'].isin(websites_to_remove))] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5) Remove the rows where the top-level domains of the website are in the banned_domains.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new column (tld) by extrating the top level domains from the website column\n",
    "test_task_data['tld'] = test_task_data['website'].str.extract(r'(?:https?://)?(?:www\\.)?[^/]+\\.(\\w+)', expand=False) # using regex\n",
    "\n",
    "# getting all domains from banned_domains_data datadrame and remoovin the \".\" that preceeds them into a list\n",
    "banned_domains = banned_domains_data['urls'].str.replace(r'^\\.', '', regex=True).tolist()\n",
    "\n",
    "# removing rows where the TLD is in the banned domains list\n",
    "test_task_data = test_task_data[~test_task_data['tld'].isin(banned_domains)]\n",
    "\n",
    "# droping the just created 'tld' column as it was just temporary\n",
    "test_task_data = test_task_data.drop(columns=['tld'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6) Remove the rows with entities the descriptions of which contain any words from banned_words.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting all banned words from banned_words_data dataframe into a list\n",
    "banned_words = banned_words_data['words'].tolist()\n",
    "\n",
    "# creating a regex pattern that matches any of the banned words (case insensitive)\n",
    "pattern = '|'.join(banned_words)  # joining the words with '|' to create an OR condition\n",
    "pattern = r'\\b(?:' + pattern + r')\\b'  # adding word boundaries for exact matches\n",
    "\n",
    "# removing all rows where description contains any of the banned words\n",
    "test_task_data = test_task_data[~test_task_data['description'].str.contains(pattern, case=False, na=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7) The column \"categories\" contains lists of dictionaries with names of categories for every entity. Create a new column \"categories_list\" with lists of extracted names of categories from these lists of dictionaries (key 'value')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "# converting the string representation of lists to actual lists of dictionaries\n",
    "test_task_data['categories'] = test_task_data['categories'].apply(ast.literal_eval)\n",
    "\n",
    "# creating a new column (categories_list) by extracting the values associated with the \"value\" key\n",
    "test_task_data['categories_list'] = test_task_data['categories'].apply(\n",
    "    lambda x: [category['value'] for category in x] if isinstance(x, list) else []\n",
    ") # using a lambda function to achieve this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8) The column \"location\" contains dictionaries with lists of locations at different scale, namely city, region and country, plus continent. Extract cities, regions and countries for every entity and put every list in a separate column named accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting location column into actual lists of dictionaries\n",
    "test_task_data['location'] = test_task_data['location'].apply(ast.literal_eval)\n",
    "\n",
    "# defining a function to extract the value based on location_type\n",
    "def extract_location(locations, loc_type):\n",
    "    return [loc['value'] for loc in locations if loc['location_type'] == loc_type]\n",
    "\n",
    "# creating separate columns for city, region, and country\n",
    "test_task_data['city'] = test_task_data['location'].apply(lambda x: extract_location(x, 'city'))\n",
    "test_task_data['region'] = test_task_data['location'].apply(lambda x: extract_location(x, 'region'))\n",
    "test_task_data['country'] = test_task_data['location'].apply(lambda x: extract_location(x, 'country'))\n",
    "# test_task_data['continent'] = test_task_data['location'].apply(lambda x: extract_location(x, 'continent'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9) Sum up the investments from funding_data.csv per entity (we recommend using uuid) and add a column in the main dataframe with total investment for every entity based on what you calculated. Not all entities will have investments and not all investment data will be used, so don't worry about blank spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new dataframe(investment_per_uuid) that contains total money raised per uuid\n",
    "investment_per_uuid = funding_data.groupby('uuid', as_index=False)['money_raised'].sum()\n",
    "\n",
    "# merging the two dataframes on the 'uuid' column\n",
    "test_task_data = test_task_data.merge(investment_per_uuid[['uuid', 'money_raised']], on='uuid', how='left')\n",
    "\n",
    "# renaming the 'money_raised' column to 'total_investments'\n",
    "test_task_data['total_investments'] = test_task_data['money_raised']\n",
    "\n",
    "# dropping the 'money_raised' column\n",
    "test_task_data.drop(columns=['money_raised'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>uuid</th>\n",
       "      <th>website</th>\n",
       "      <th>Name</th>\n",
       "      <th>description</th>\n",
       "      <th>valuation_usd</th>\n",
       "      <th>categories</th>\n",
       "      <th>location</th>\n",
       "      <th>categories_list</th>\n",
       "      <th>city</th>\n",
       "      <th>region</th>\n",
       "      <th>country</th>\n",
       "      <th>total_investments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3316</th>\n",
       "      <td>991</td>\n",
       "      <td>dee4d79d-692a-46fd-bfc4-13109c64efa3</td>\n",
       "      <td>http://circlelabs.xyz/</td>\n",
       "      <td>circle labs</td>\n",
       "      <td>circle labs is a platform that enables anyone ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'entity_def_id': 'category', 'permalink': 'a...</td>\n",
       "      <td>[{'permalink': 'san-francisco-california', 'uu...</td>\n",
       "      <td>[Apps, Consumer, Gaming, Virtual Reality]</td>\n",
       "      <td>[San Francisco]</td>\n",
       "      <td>[California]</td>\n",
       "      <td>[United States]</td>\n",
       "      <td>4200000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3317</th>\n",
       "      <td>994</td>\n",
       "      <td>5b61e4c8-756a-7a0e-ce42-b3a76da009db</td>\n",
       "      <td>https://gohopscotch.com/</td>\n",
       "      <td>Hopscotch</td>\n",
       "      <td>Hopscotch is an open, mobile experiences platf...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'entity_def_id': 'category', 'permalink': 'b...</td>\n",
       "      <td>[{'permalink': 'el-segundo-california', 'uuid'...</td>\n",
       "      <td>[B2B, E-Learning, Edutainment, Financial Servi...</td>\n",
       "      <td>[El Segundo]</td>\n",
       "      <td>[California]</td>\n",
       "      <td>[United States]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3318</th>\n",
       "      <td>996</td>\n",
       "      <td>7bb0e599-7438-434e-9c45-0ab00fcff7e8</td>\n",
       "      <td>https://pabloair.com</td>\n",
       "      <td>PABLO AIR</td>\n",
       "      <td>PABLO AIR is creating various mobility busines...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'entity_def_id': 'category', 'permalink': 'a...</td>\n",
       "      <td>[{'permalink': 'incheon-inchon-jikhalsi', 'uui...</td>\n",
       "      <td>[Aerospace, Delivery Service, Drone Management...</td>\n",
       "      <td>[Incheon]</td>\n",
       "      <td>[Inch'on-jikhalsi]</td>\n",
       "      <td>[South Korea]</td>\n",
       "      <td>9140484.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3319</th>\n",
       "      <td>998</td>\n",
       "      <td>cbe17592-d84d-46d2-a2f4-b19f7041626e</td>\n",
       "      <td>https://spencerhealthsolutions.com</td>\n",
       "      <td>Spencer Health Solutions</td>\n",
       "      <td>Spencer Health Solutions is a developer of an ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'entity_def_id': 'category', 'permalink': 'h...</td>\n",
       "      <td>[{'permalink': 'morrisville-north-carolina', '...</td>\n",
       "      <td>[Health Care, Medical Device, Pharmaceutical]</td>\n",
       "      <td>[Morrisville]</td>\n",
       "      <td>[North Carolina]</td>\n",
       "      <td>[United States]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3320</th>\n",
       "      <td>999</td>\n",
       "      <td>8b0ec269-abfc-4b37-b808-fe2d3b83b78f</td>\n",
       "      <td>https://waste4change.com</td>\n",
       "      <td>Waste4Change</td>\n",
       "      <td>Waste4Change is a leading waste management pla...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'entity_def_id': 'category', 'permalink': 'c...</td>\n",
       "      <td>[{'permalink': 'jakarta-jakarta-raya', 'uuid':...</td>\n",
       "      <td>[CleanTech, GreenTech, Recycling, Waste Manage...</td>\n",
       "      <td>[Jakarta]</td>\n",
       "      <td>[Jakarta Raya]</td>\n",
       "      <td>[Indonesia]</td>\n",
       "      <td>5000000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                  uuid  \\\n",
       "3316         991  dee4d79d-692a-46fd-bfc4-13109c64efa3   \n",
       "3317         994  5b61e4c8-756a-7a0e-ce42-b3a76da009db   \n",
       "3318         996  7bb0e599-7438-434e-9c45-0ab00fcff7e8   \n",
       "3319         998  cbe17592-d84d-46d2-a2f4-b19f7041626e   \n",
       "3320         999  8b0ec269-abfc-4b37-b808-fe2d3b83b78f   \n",
       "\n",
       "                                 website                      Name  \\\n",
       "3316              http://circlelabs.xyz/               circle labs   \n",
       "3317            https://gohopscotch.com/                 Hopscotch   \n",
       "3318                https://pabloair.com                 PABLO AIR   \n",
       "3319  https://spencerhealthsolutions.com  Spencer Health Solutions   \n",
       "3320            https://waste4change.com              Waste4Change   \n",
       "\n",
       "                                            description  valuation_usd  \\\n",
       "3316  circle labs is a platform that enables anyone ...            NaN   \n",
       "3317  Hopscotch is an open, mobile experiences platf...            NaN   \n",
       "3318  PABLO AIR is creating various mobility busines...            NaN   \n",
       "3319  Spencer Health Solutions is a developer of an ...            NaN   \n",
       "3320  Waste4Change is a leading waste management pla...            NaN   \n",
       "\n",
       "                                             categories  \\\n",
       "3316  [{'entity_def_id': 'category', 'permalink': 'a...   \n",
       "3317  [{'entity_def_id': 'category', 'permalink': 'b...   \n",
       "3318  [{'entity_def_id': 'category', 'permalink': 'a...   \n",
       "3319  [{'entity_def_id': 'category', 'permalink': 'h...   \n",
       "3320  [{'entity_def_id': 'category', 'permalink': 'c...   \n",
       "\n",
       "                                               location  \\\n",
       "3316  [{'permalink': 'san-francisco-california', 'uu...   \n",
       "3317  [{'permalink': 'el-segundo-california', 'uuid'...   \n",
       "3318  [{'permalink': 'incheon-inchon-jikhalsi', 'uui...   \n",
       "3319  [{'permalink': 'morrisville-north-carolina', '...   \n",
       "3320  [{'permalink': 'jakarta-jakarta-raya', 'uuid':...   \n",
       "\n",
       "                                        categories_list             city  \\\n",
       "3316          [Apps, Consumer, Gaming, Virtual Reality]  [San Francisco]   \n",
       "3317  [B2B, E-Learning, Edutainment, Financial Servi...     [El Segundo]   \n",
       "3318  [Aerospace, Delivery Service, Drone Management...        [Incheon]   \n",
       "3319      [Health Care, Medical Device, Pharmaceutical]    [Morrisville]   \n",
       "3320  [CleanTech, GreenTech, Recycling, Waste Manage...        [Jakarta]   \n",
       "\n",
       "                  region          country  total_investments  \n",
       "3316        [California]  [United States]          4200000.0  \n",
       "3317        [California]  [United States]                NaN  \n",
       "3318  [Inch'on-jikhalsi]    [South Korea]          9140484.0  \n",
       "3319    [North Carolina]  [United States]                NaN  \n",
       "3320      [Jakarta Raya]      [Indonesia]          5000000.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_task_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"test_task.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
